cmake_minimum_required(VERSION 3.18)
project(flash_attention_standalone LANGUAGES CUDA CXX)

# Set C++ and CUDA standards
set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CUDA_STANDARD 17)
set(CMAKE_CUDA_STANDARD_REQUIRED ON)

# Find CUDA
find_package(CUDAToolkit REQUIRED)

# Check CUDA version for Hopper support
if(CUDAToolkit_VERSION VERSION_LESS "11.8")
    message(FATAL_ERROR "CUDA 11.8+ is required for Hopper (SM90) support")
endif()

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_SOURCE_DIR}/../
    ${CMAKE_CURRENT_SOURCE_DIR}/../csrc/flash_attn/src
    ${CMAKE_CURRENT_SOURCE_DIR}/../csrc/cutlass/include
    ${CMAKE_CURRENT_SOURCE_DIR}/../hopper
    ${CUDAToolkit_INCLUDE_DIRS}
)

# Define preprocessor macros
add_compile_definitions(
    FLASHATTENTION_STANDALONE
    FLASHATTENTION_DISABLE_BACKWARD
    FLASH_NAMESPACE=flash
)

# CUDA compilation flags
set(CUDA_FLAGS
    -O3
    -std=c++17
    -gencode arch=compute_90a,code=sm_90a
    -U__CUDA_NO_HALF_OPERATORS__
    -U__CUDA_NO_HALF_CONVERSIONS__
    -U__CUDA_NO_HALF2_OPERATORS__
    -U__CUDA_NO_BFLOAT16_CONVERSIONS__
    --expt-relaxed-constexpr
    --expt-extended-lambda
    --use_fast_math
    -DCUTE_SM90_EXTENDED_MMA_SHAPES_ENABLED
    -DCUTLASS_ENABLE_GDC_FOR_SM90
    -DNDEBUG
    -Xcompiler=-fPIC
    -Xcompiler=-Wall
)

# ============================================================================
# ULTIMATE SEPARATION: Each kernel as a SHARED library
# This ensures complete isolation and no register sharing
# ============================================================================

# Function to create a kernel as a shared library
function(add_kernel_library kernel_name kernel_source)
    # Create shared library for this kernel
    add_library(${kernel_name} SHARED ${kernel_source})

    # Set compilation flags
    target_compile_options(${kernel_name} PRIVATE
        $<$<COMPILE_LANGUAGE:CUDA>:${CUDA_FLAGS}>
    )

    # Enable separable compilation
    set_target_properties(${kernel_name} PROPERTIES
        CUDA_SEPARABLE_COMPILATION ON
        POSITION_INDEPENDENT_CODE ON
        CUDA_RESOLVE_DEVICE_SYMBOLS ON
    )

    # Link CUDA runtime
    target_link_libraries(${kernel_name} PRIVATE
        CUDA::cudart
    )

    message(STATUS "Added kernel library: ${kernel_name}")
endfunction()

# Create shared libraries for each kernel
add_kernel_library(kernel_fp16_hdim128
    ${CMAKE_CURRENT_SOURCE_DIR}/kernels/kernel_fp16_hdim128.cu)

add_kernel_library(kernel_fp16_hdim256
    ${CMAKE_CURRENT_SOURCE_DIR}/kernels/kernel_fp16_hdim256.cu)

add_kernel_library(kernel_bf16_hdim128
    ${CMAKE_CURRENT_SOURCE_DIR}/kernels/kernel_bf16_hdim128.cu)

add_kernel_library(kernel_bf16_hdim256
    ${CMAKE_CURRENT_SOURCE_DIR}/kernels/kernel_bf16_hdim256.cu)

add_kernel_library(kernel_fp8_e4m3_hdim128
    ${CMAKE_CURRENT_SOURCE_DIR}/kernels/kernel_fp8_e4m3_hdim128.cu)

# ============================================================================
# API wrapper (separate shared library)
# ============================================================================

add_library(flash_api SHARED
    ${CMAKE_CURRENT_SOURCE_DIR}/src/flash_api.cu
)

target_compile_options(flash_api PRIVATE
    $<$<COMPILE_LANGUAGE:CUDA>:${CUDA_FLAGS}>
)

set_target_properties(flash_api PROPERTIES
    CUDA_SEPARABLE_COMPILATION ON
    POSITION_INDEPENDENT_CODE ON
)

# Link all kernel libraries
target_link_libraries(flash_api PUBLIC
    kernel_fp16_hdim128
    kernel_fp16_hdim256
    kernel_bf16_hdim128
    kernel_bf16_hdim256
    kernel_fp8_e4m3_hdim128
    CUDA::cudart
)

# ============================================================================
# Main executable
# ============================================================================

add_executable(flash_attention_exec
    ${CMAKE_CURRENT_SOURCE_DIR}/src/main.cpp
)

# Link only the API library (which brings in kernel libraries)
target_link_libraries(flash_attention_exec PRIVATE
    flash_api
    CUDA::cudart
    CUDA::cuda_driver
)

set_target_properties(flash_attention_exec PROPERTIES
    RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}
)

# ============================================================================
# Alternative: Static executable with dlopen for kernels
# ============================================================================

option(BUILD_MODULAR "Build with dynamically loadable kernel modules" OFF)

if(BUILD_MODULAR)
    add_executable(flash_attention_modular
        ${CMAKE_CURRENT_SOURCE_DIR}/src/main_modular.cpp
    )

    target_link_libraries(flash_attention_modular PRIVATE
        CUDA::cudart
        CUDA::cuda_driver
        ${CMAKE_DL_LIBS}  # For dlopen/dlsym
    )
endif()

# ============================================================================
# Print configuration summary
# ============================================================================

message(STATUS "")
message(STATUS "Flash Attention Standalone Configuration:")
message(STATUS "  CUDA Version: ${CUDAToolkit_VERSION}")
message(STATUS "  CUDA Architecture: SM90a (Hopper)")
message(STATUS "  Build type: ${CMAKE_BUILD_TYPE}")
message(STATUS "")
message(STATUS "Kernel libraries (shared):")
message(STATUS "  - kernel_fp16_hdim128.so")
message(STATUS "  - kernel_fp16_hdim256.so")
message(STATUS "  - kernel_bf16_hdim128.so")
message(STATUS "  - kernel_bf16_hdim256.so")
message(STATUS "  - kernel_fp8_e4m3_hdim128.so")
message(STATUS "")
message(STATUS "This configuration ensures complete kernel isolation")
message(STATUS "Each kernel runs in its own shared library space")
message(STATUS "")